[![\\ \documentclass{article} \\ \usepackage{graphicx} % Required for inserting images \\ \usepackage{hyperref} \\ \usepackage{amsmath} \\ \title{Report} \\ \author{Ashwajit Singh} \\ \date{June 2024} \\  \\ \begin{document} \\  \\ \maketitle \\  \\ \section{Introduction} \\  \\ The paper covers a new method of anti-aliasing that aliases the frequency response of a traditional low pass filter in order to improve stopband suppression. It achieves this by mixing the input signal with a signal $d(t)$ before passing the signal through a low pass filter. The advantage that this method (called Filtering by Aliasing or FA) has is that it doesn't require additional stages for its operation, unlike some of the other techniques discussed in the paper, like Integration Sampling.   \\  \\ The intuition behind FA is that a periodic spreading signal creates aliases of the frequency response of the filter (as will be explained later), and so we can ensure that these aliases overlap in such a way that they improve the frequency response of the filter. \\  \\ \section{Background} \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 0.5]{diagram_fa.png} \\ \end{figure} \\  \\ The intuition however, does not give us the exact value of $d(t)$ as shown in the figure above, since the exact weights of the aliased thing = \\ From the perspective of the input signal $u(t)$, the signal is first multiplied by $d(t)$, and this signal then goes through the filter with frequency response $H(f)$, which is equivalent to a convolution with $h(t)$. Note that $d(t)$ here is a periodic signal with periodicity $T_s$, where $nT_s$ is the sampling time and $nF_s$ is the corresponding sample frequency. This finally gives us the output \\  \\ \begin{equation} \\     y(t) = \int_{-\infty}^{+\infty}u(\tau)d(\tau)h(t-\tau)d\tau \\ \end{equation} \\  \\ \noindent \\ and using the convolution theorem the frequency response is \\  \\ \begin{equation} \\     Y(f) = H(f) \int_{-\infty}^{+\infty} U(f)D(f)df \\ \end{equation} \\  \\ We then use the fact that $d(t)$ is a periodic signal to reduce $D(f)$ to just its tone values $D_m$ (i.e. the amplitude of the signal at frequencies $mF_s$.) The idea here is that even before sampling we have aliases of $U(f)$, and we take advantage of this to improve the filter as seen from the output. \\  \\ \begin{equation} \\     Y(f) = H(f) \sum_{m=-\infty}^{+\infty} D_mU(f-mF_s) \\ \end{equation} \\  \\ However, the effect of this spreading signal is clearer if we attempt to determine the frequency response effective filter (let's say $G(f)$), combining the effect of $d(t)$ with the existing filter $h(t)$. Let's assume we sample at $nT_s$. Using the periodicity of $d(t)$ we can then write the output $y[n]$ (using (1)) as  \\  \\ \begin{equation} \\     y[n] = \int_{-\infty}^{+\infty}u(\tau)d(\tau - nT_s)h(nT_s-\tau)d\tau \\ \end{equation} \\  \\ Thus we are effectively convolving our input with a signal $g(t) = h(t)d(-t)$. The intuition behind FA is clearer if we treat the spreading signal $d(t)$ as part of the whole transfer function, and so if the impulse response of the filter being used (in this case a single pole filter) is $h(t)$, the system as a whole has impulse response $h(t)d(-t)$. The frequency response of this effective filter is now simply \\  \\ \begin{equation} \\     G(f) = \sum_{m=-\infty}^{+\infty} D_mH(f+mF_s) \\ \end{equation} \\  \\ It is now clear that we have aliased the frequency response of the filter $H(f)$, and if we now find optimal values of $D_m$ (which act as the weights of the frequency shifted $H(f)$), we can achieve far better results. \\  \\ \section{Reproducing the results} \\  \\ There are two ways of approaching the problem of finding $d(t)$ given the constraints that we want to impose on it, with a marginal difference. We can either  \\  \\ \begin{itemize} \\     \item apply the passband and stopband constraints shown below in the frequency domain, using the idea of oversampling, or  \\     \item convert the problem to the time domain, by finding the impulse response of the optimal FIR filter using the Parks-McClellan algorithm \\ \end{itemize}  \\ Fundamentally, the goal here is that given some filter $H(f)$, we can find the optimal $D_m$ (or the corresponding signal $d(t)$ so as to satisfy the constraints we impose on the passband and stopband. These constraints could be varied depending on the type of filter desired, but since here we want a simple low-pass anti-aliasing filter, the constraints imposed on our effective filter $G(f)$ are \\  \\ \begin{align*} \\     1-\delta_{pass} &\leq |G(f)| \leq 1 & \\     f \in [0, f_{pass}] \\ \\     |G(f)| &\leq \delta_{stop} & f \in [f_{stop}, +\infty] \\ \end{align*} \\  \\ Both approaches use the idea of looking at our effective filter as a finite impulse response (or FIR) filter (as described below), and using that to simplify the problem. \\  \\ \subsection{Optimising an FIR Filter} \\  \\ An FIR (finite impulse response) filter is described by  \\ \begin{equation} \\     y(t) = \sum_{i=0}^{n-1} h(i)u(t-i) \\ \end{equation} \\ with the frequency response of the filter $H(\omega)$ given by \\ \begin{equation} \\     H(\omega) = h(0)+h(1)e^{-j\omega}+...+h(n-1)e^{-j(n-1)\omega} \\ \end{equation} \\  \\ \subsection{Method 1: Parks-McClellan algorithm} \\  \\ The Parks-McClellan algorithm is an iterative process that takes as its input the desired frequency constraints and the order of the filter, and provides the impulse response (or $h(i)$ as described in $(6)$ to meet those constraints.) Here since we want to create a low pass filter, we impose the passband constraint ($f \in [0, f_{pass}]$ of $G(\omega) = 1$ and the stopband constraint ($f \in [f_{stop}, \infty]$ of $G(\omega) = 0$. In reproducing the results I took the order of the filter to be 20 (which in turn determines the number of tone values $D_m$ we can determine.) The algorithm then works iteratively in the following steps:  \\  c) Add the points where $E(\omega)$ attains its local maxima to the original set, d) Repeat the process until the maximum error is within the tolerance we set. \\  \\ \begin{enumerate} \\     \item Choose a set of frequencies and find the best Chebyshev approximation over the set of frequencies, \\     \item Calculate the error function (or deviation from the constraints that we had imposed),  \\     \item Update the points where $E(\omega)$ attains its local maxima to the the new set over which you approximate, \\     \item Repeat the process until the maximum error is within the tolerance we set. \\ \end{enumerate} \\  \\ Note here that this differs from the original convex optimisation problem in that we aren't directly minimising $\delta_{stop}$, but are instead minimising the error function overall to within the set tolerance. I started off by making the ideal FIR function (i.e. the function with respect to which the error is calculated) a low pass FIR filter, with a linear decrease from 1 to 0 from $f_{pass}$ to $f_{stop}$. This however results in much weaker stopband suppression than if we used the other method, since it tries to minimise the error in the passband as well (i.e. keep the transfer function as close to 1 as possible.) This was fixed by giving the stopband a much higher weight, thus ensuring that it was minimised at the cost of the passband. Thus the only conditions on the filter are (i) $G(\omega) = 1$ for $\omega = 0$ and (ii) minimising $G(\omega)$ for $\omega > \omega_{stop}$. This gives us results nearly identical to if we use convex optimisation in the frequency domain. \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 0.8]{ideal.png} \\ \end{figure} \\  \\ \subsection{Method 2: Convex optimisation in FA} \\  \\ Here, we want to optimise for $H(\omega)$ as in $(7)$, but we cannot apply passband and stopband constraints to $H(\omega)$ and treat it as a convex problem, so we apply a change of variable, using the idea of autocorrelation coefficients $r(t) = \sum_{i = -n+1}^{n-1} h(i)h(i+t)$. We then get  \\  \\ \begin{equation} \\     R(\omega) = \sum_{t\in Z} r(t) e^{-j\omega t} = r(0) + \sum_{i=1}^{n-1}2r(t)cos(\omega t) = |H(\omega)^2| \\ \end{equation} \\  \\ This is now a convex problem in $r(t)$, so we apply the same constraints on the squared magnitude of $H(\omega)$ to obtain the optimum values of $r(t)$. \\  \\ In the results below I took $H(f)$ to be a single pole filter. While a non-linear programming solver can be used to solve this problem in its existing form, we can describe it in convex form by approximating it and enforcing a change of variable. \\  \\ First, we describe the FA response for a discrete time variant, with a pre-sampling rate of $NF_s$ (ensuring N is sufficiently large such that the aliases due to the pre-sampling are in a frequency range that is sufficiently suppressed.) This gives us \\  \\ \begin{equation} \\     G(\omega) = \sum_{m=-\frac{N-1}{2}}^{+\frac{N-1}{2}} D_m H(\omega + \frac{2\pi m}{N}) \\ \end{equation} \\  \\ where $D_m = D(\frac{2\pi m}{N})$. Given the frequency response $H(\omega) = \frac{1}{1 - \alpha e^{-j\omega}}$ and (6), we can rewrite it as  \\  \\ \begin{equation} \\     G(\omega) = \frac{\sum_{m = -(N-1)/2}^{(N-1)/2}D_m \prod_{\mu \neq m}(1-\alpha e^{j(\omega + \frac{2\pi\mu}{N})})}{\prod_{\mu \neq m}^{(N-1)/2} (1-\alpha e^{j(\omega+\frac{2\pi m}{N})})} \\ \end{equation} \\  \\ We write this in terms of time domain samples $d[k]$, giving us \\  \\ \begin{equation} \\     G(\omega) = \frac{\sum_{k=0}^{N-1}d[-k]\alpha^k e^{-j\omega k}}{1 - \alpha^N e^{-j\omega N}} \\ \end{equation} \\  \\ We can now adapt the idea explained above to convert the constraints on $G(\omega)$ to a convex problem. We write the squared magnitude of $G(\omega)$ (say $R(\omega)$) in terms of the autocorrelation coefficients of $g[k] = h[k]d[-k]$, $r(t) = \sum_{i = -n+1}^{n-1} g(i)g(i+t)$, where $h[k] = \alpha^k$. Since the denominator is independent of $\alpha$ and $d[k]$, we can treat the numerator as an FIR filter. This finally gives us  \\  \\ \begin{equation} \\     R(\omega) =  r(0) + \sum_{i=1}^{n-1}2r(t)cos(\omega t) = |1-\alpha^Ne^{-j\omega N}|H(\omega)^2 \\ \end{equation} \\  \\ Optimising $|H(\omega)^2|$ is a convex problem, as it is a linear combination of the optimisation variables $r(t)$, and so we can have lower bounds for $R(\omega)$ as required by the passband constraint. Once we have the problem in this form, a package like cvx can be used to give the optimal value of $d[k]$, minimising $\delta_{stop}$. To determine $d[k]$ from this, we apply spectral factorisation on $R(\omega)$ to determine the minimum phase $G(\omega)$. There is then a one-one correlation between $G(\omega)$, and $d[k]$ and $\alpha$ (although here $\alpha$ was taken to be fixed), finally giving us the desired signal $d(t)$. \\  \\ \section{Issues} \\  \\ I was not able to demonstrate this in LTSpice as it could not handle delta functions (which the signal d(t) consists of as a periodic function) well when plotting the frequency response, so I plotted the transfer function in MATLAB instead, assuming a single pole RC filter. While solving by convex factorisation, I was also unable to recover the minimum phase $G(\omega)$ from $|G(\omega)^2|$ as described in the paper as the MATLAB function spectralfact was not able to process the transfer function. I tried using the autocorrelation coefficients to obtain the original $d(t)$ as outlined in the paper above, but was again unable to obtain an output from the function. However, these issues were solved using the Parks-McClellan algorithm.  \\  \\ \section{Other Considerations} \\  \\ When implementing FA in practical applications, there are some additional considerations. First, the spreader signal $d(t)$ has a finite resolution, and so the stopband suppression depends on the quantisation error. Aside from increasing the number of bits, this error can also be reduced by dithering, which is intentionally adding noise before quantisation to reduce the effect of the periodicity of the quantisation noise. \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 1]{final.png} \\ \end{figure} \\  \\ As discussed earlier, the spreader rate (or $NF_s$) also affects the performance of the filter. This is because the gain stage (where the spreading signal is mixed with the input), is digitally controlled with frequency $NF_s$. As long as $N$ is sufficiently high however, the impact of the aliased pass-bands is negligible as usually, the rest of the circuit is inherently low-pass. \\  \\ \section{Final Results} \\  \\ The magnitude of the FA filter $|G(\omega)|$ is plotted below for different values of $f_{stop}$ along with the frequency response of a single pole filter (with $\alpha = 0.9$.) From the plots it is clear that the dropoff is much faster for an FA filter, and the stopband suppression is greatly improved. As can be seen from the plots, a balance has to be struck between how fast the dropoff is (determined by $f_{stop}$) and the stopband suppression ($\delta_{stop}$, the variable minimised while optimising.) We have also compared the results from the two methods used to find the optimal transfer function,  \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 0.8]{logcomb.png} \\ \caption{Using convex optimisation} \\ \end{figure} \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 0.8]{log_parks.png} \\ \caption{Using Parks-McClellan algorithm} \\ \end{figure} \\  \\ \begin{figure}[h!] \\ \centering \\ \includegraphics[scale = 0.8]{comparison.png} \\ \caption{Comparing the two methods with $f_{stop} = 1.5F_s$} \\ \end{figure} \\  \\  \\ \end{document} \\ ](https://latex.codecogs.com/svg.latex?%5C%5C%20%5Cdocumentclass%7Barticle%7D%20%5C%5C%20%5Cusepackage%7Bgraphicx%7D%20%25%20Required%20for%20inserting%20images%20%5C%5C%20%5Cusepackage%7Bhyperref%7D%20%5C%5C%20%5Cusepackage%7Bamsmath%7D%20%5C%5C%20%5Ctitle%7BReport%7D%20%5C%5C%20%5Cauthor%7BAshwajit%20Singh%7D%20%5C%5C%20%5Cdate%7BJune%202024%7D%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bdocument%7D%20%5C%5C%20%20%5C%5C%20%5Cmaketitle%20%5C%5C%20%20%5C%5C%20%5Csection%7BIntroduction%7D%20%5C%5C%20%20%5C%5C%20The%20paper%20covers%20a%20new%20method%20of%20anti-aliasing%20that%20aliases%20the%20frequency%20response%20of%20a%20traditional%20low%20pass%20filter%20in%20order%20to%20improve%20stopband%20suppression.%20It%20achieves%20this%20by%20mixing%20the%20input%20signal%20with%20a%20signal%20%24d(t)%24%20before%20passing%20the%20signal%20through%20a%20low%20pass%20filter.%20The%20advantage%20that%20this%20method%20(called%20Filtering%20by%20Aliasing%20or%20FA)%20has%20is%20that%20it%20doesn't%20require%20additional%20stages%20for%20its%20operation%2C%20unlike%20some%20of%20the%20other%20techniques%20discussed%20in%20the%20paper%2C%20like%20Integration%20Sampling.%20%20%20%5C%5C%20%20%5C%5C%20The%20intuition%20behind%20FA%20is%20that%20a%20periodic%20spreading%20signal%20creates%20aliases%20of%20the%20frequency%20response%20of%20the%20filter%20(as%20will%20be%20explained%20later)%2C%20and%20so%20we%20can%20ensure%20that%20these%20aliases%20overlap%20in%20such%20a%20way%20that%20they%20improve%20the%20frequency%20response%20of%20the%20filter.%20%5C%5C%20%20%5C%5C%20%5Csection%7BBackground%7D%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%200.5%5D%7Bdiagram_fa.png%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20The%20intuition%20however%2C%20does%20not%20give%20us%20the%20exact%20value%20of%20%24d(t)%24%20as%20shown%20in%20the%20figure%20above%2C%20since%20the%20exact%20weights%20of%20the%20aliased%20thing%20%3D%20%5C%5C%20From%20the%20perspective%20of%20the%20input%20signal%20%24u(t)%24%2C%20the%20signal%20is%20first%20multiplied%20by%20%24d(t)%24%2C%20and%20this%20signal%20then%20goes%20through%20the%20filter%20with%20frequency%20response%20%24H(f)%24%2C%20which%20is%20equivalent%20to%20a%20convolution%20with%20%24h(t)%24.%20Note%20that%20%24d(t)%24%20here%20is%20a%20periodic%20signal%20with%20periodicity%20%24T_s%24%2C%20where%20%24nT_s%24%20is%20the%20sampling%20time%20and%20%24nF_s%24%20is%20the%20corresponding%20sample%20frequency.%20This%20finally%20gives%20us%20the%20output%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20y(t)%20%3D%20%5Cint_%7B-%5Cinfty%7D%5E%7B%2B%5Cinfty%7Du(%5Ctau)d(%5Ctau)h(t-%5Ctau)d%5Ctau%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20%5Cnoindent%20%5C%5C%20and%20using%20the%20convolution%20theorem%20the%20frequency%20response%20is%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20Y(f)%20%3D%20H(f)%20%5Cint_%7B-%5Cinfty%7D%5E%7B%2B%5Cinfty%7D%20U(f)D(f)df%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20We%20then%20use%20the%20fact%20that%20%24d(t)%24%20is%20a%20periodic%20signal%20to%20reduce%20%24D(f)%24%20to%20just%20its%20tone%20values%20%24D_m%24%20(i.e.%20the%20amplitude%20of%20the%20signal%20at%20frequencies%20%24mF_s%24.)%20The%20idea%20here%20is%20that%20even%20before%20sampling%20we%20have%20aliases%20of%20%24U(f)%24%2C%20and%20we%20take%20advantage%20of%20this%20to%20improve%20the%20filter%20as%20seen%20from%20the%20output.%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20Y(f)%20%3D%20H(f)%20%5Csum_%7Bm%3D-%5Cinfty%7D%5E%7B%2B%5Cinfty%7D%20D_mU(f-mF_s)%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20However%2C%20the%20effect%20of%20this%20spreading%20signal%20is%20clearer%20if%20we%20attempt%20to%20determine%20the%20frequency%20response%20effective%20filter%20(let's%20say%20%24G(f)%24)%2C%20combining%20the%20effect%20of%20%24d(t)%24%20with%20the%20existing%20filter%20%24h(t)%24.%20Let's%20assume%20we%20sample%20at%20%24nT_s%24.%20Using%20the%20periodicity%20of%20%24d(t)%24%20we%20can%20then%20write%20the%20output%20%24y%5Bn%5D%24%20(using%20(1))%20as%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20y%5Bn%5D%20%3D%20%5Cint_%7B-%5Cinfty%7D%5E%7B%2B%5Cinfty%7Du(%5Ctau)d(%5Ctau%20-%20nT_s)h(nT_s-%5Ctau)d%5Ctau%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20Thus%20we%20are%20effectively%20convolving%20our%20input%20with%20a%20signal%20%24g(t)%20%3D%20h(t)d(-t)%24.%20The%20intuition%20behind%20FA%20is%20clearer%20if%20we%20treat%20the%20spreading%20signal%20%24d(t)%24%20as%20part%20of%20the%20whole%20transfer%20function%2C%20and%20so%20if%20the%20impulse%20response%20of%20the%20filter%20being%20used%20(in%20this%20case%20a%20single%20pole%20filter)%20is%20%24h(t)%24%2C%20the%20system%20as%20a%20whole%20has%20impulse%20response%20%24h(t)d(-t)%24.%20The%20frequency%20response%20of%20this%20effective%20filter%20is%20now%20simply%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20G(f)%20%3D%20%5Csum_%7Bm%3D-%5Cinfty%7D%5E%7B%2B%5Cinfty%7D%20D_mH(f%2BmF_s)%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20It%20is%20now%20clear%20that%20we%20have%20aliased%20the%20frequency%20response%20of%20the%20filter%20%24H(f)%24%2C%20and%20if%20we%20now%20find%20optimal%20values%20of%20%24D_m%24%20(which%20act%20as%20the%20weights%20of%20the%20frequency%20shifted%20%24H(f)%24)%2C%20we%20can%20achieve%20far%20better%20results.%20%5C%5C%20%20%5C%5C%20%5Csection%7BReproducing%20the%20results%7D%20%5C%5C%20%20%5C%5C%20There%20are%20two%20ways%20of%20approaching%20the%20problem%20of%20finding%20%24d(t)%24%20given%20the%20constraints%20that%20we%20want%20to%20impose%20on%20it%2C%20with%20a%20marginal%20difference.%20We%20can%20either%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bitemize%7D%20%5C%5C%20%20%20%20%20%5Citem%20apply%20the%20passband%20and%20stopband%20constraints%20shown%20below%20in%20the%20frequency%20domain%2C%20using%20the%20idea%20of%20oversampling%2C%20or%20%20%5C%5C%20%20%20%20%20%5Citem%20convert%20the%20problem%20to%20the%20time%20domain%2C%20by%20finding%20the%20impulse%20response%20of%20the%20optimal%20FIR%20filter%20using%20the%20Parks-McClellan%20algorithm%20%5C%5C%20%5Cend%7Bitemize%7D%20%20%5C%5C%20Fundamentally%2C%20the%20goal%20here%20is%20that%20given%20some%20filter%20%24H(f)%24%2C%20we%20can%20find%20the%20optimal%20%24D_m%24%20(or%20the%20corresponding%20signal%20%24d(t)%24%20so%20as%20to%20satisfy%20the%20constraints%20we%20impose%20on%20the%20passband%20and%20stopband.%20These%20constraints%20could%20be%20varied%20depending%20on%20the%20type%20of%20filter%20desired%2C%20but%20since%20here%20we%20want%20a%20simple%20low-pass%20anti-aliasing%20filter%2C%20the%20constraints%20imposed%20on%20our%20effective%20filter%20%24G(f)%24%20are%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Balign*%7D%20%5C%5C%20%20%20%20%201-%5Cdelta_%7Bpass%7D%20%26%5Cleq%20%7CG(f)%7C%20%5Cleq%201%20%26%20%5C%5C%20%20%20%20%20f%20%5Cin%20%5B0%2C%20f_%7Bpass%7D%5D%20%5C%5C%20%5C%5C%20%20%20%20%20%7CG(f)%7C%20%26%5Cleq%20%5Cdelta_%7Bstop%7D%20%26%20f%20%5Cin%20%5Bf_%7Bstop%7D%2C%20%2B%5Cinfty%5D%20%5C%5C%20%5Cend%7Balign*%7D%20%5C%5C%20%20%5C%5C%20Both%20approaches%20use%20the%20idea%20of%20looking%20at%20our%20effective%20filter%20as%20a%20finite%20impulse%20response%20(or%20FIR)%20filter%20(as%20described%20below)%2C%20and%20using%20that%20to%20simplify%20the%20problem.%20%5C%5C%20%20%5C%5C%20%5Csubsection%7BOptimising%20an%20FIR%20Filter%7D%20%5C%5C%20%20%5C%5C%20An%20FIR%20(finite%20impulse%20response)%20filter%20is%20described%20by%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20y(t)%20%3D%20%5Csum_%7Bi%3D0%7D%5E%7Bn-1%7D%20h(i)u(t-i)%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20with%20the%20frequency%20response%20of%20the%20filter%20%24H(%5Comega)%24%20given%20by%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20H(%5Comega)%20%3D%20h(0)%2Bh(1)e%5E%7B-j%5Comega%7D%2B...%2Bh(n-1)e%5E%7B-j(n-1)%5Comega%7D%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20%5Csubsection%7BMethod%201%3A%20Parks-McClellan%20algorithm%7D%20%5C%5C%20%20%5C%5C%20The%20Parks-McClellan%20algorithm%20is%20an%20iterative%20process%20that%20takes%20as%20its%20input%20the%20desired%20frequency%20constraints%20and%20the%20order%20of%20the%20filter%2C%20and%20provides%20the%20impulse%20response%20(or%20%24h(i)%24%20as%20described%20in%20%24(6)%24%20to%20meet%20those%20constraints.)%20Here%20since%20we%20want%20to%20create%20a%20low%20pass%20filter%2C%20we%20impose%20the%20passband%20constraint%20(%24f%20%5Cin%20%5B0%2C%20f_%7Bpass%7D%5D%24%20of%20%24G(%5Comega)%20%3D%201%24%20and%20the%20stopband%20constraint%20(%24f%20%5Cin%20%5Bf_%7Bstop%7D%2C%20%5Cinfty%5D%24%20of%20%24G(%5Comega)%20%3D%200%24.%20In%20reproducing%20the%20results%20I%20took%20the%20order%20of%20the%20filter%20to%20be%2020%20(which%20in%20turn%20determines%20the%20number%20of%20tone%20values%20%24D_m%24%20we%20can%20determine.)%20The%20algorithm%20then%20works%20iteratively%20in%20the%20following%20steps%3A%20%20%5C%5C%20%20c)%20Add%20the%20points%20where%20%24E(%5Comega)%24%20attains%20its%20local%20maxima%20to%20the%20original%20set%2C%20d)%20Repeat%20the%20process%20until%20the%20maximum%20error%20is%20within%20the%20tolerance%20we%20set.%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Benumerate%7D%20%5C%5C%20%20%20%20%20%5Citem%20Choose%20a%20set%20of%20frequencies%20and%20find%20the%20best%20Chebyshev%20approximation%20over%20the%20set%20of%20frequencies%2C%20%5C%5C%20%20%20%20%20%5Citem%20Calculate%20the%20error%20function%20(or%20deviation%20from%20the%20constraints%20that%20we%20had%20imposed)%2C%20%20%5C%5C%20%20%20%20%20%5Citem%20Update%20the%20points%20where%20%24E(%5Comega)%24%20attains%20its%20local%20maxima%20to%20the%20the%20new%20set%20over%20which%20you%20approximate%2C%20%5C%5C%20%20%20%20%20%5Citem%20Repeat%20the%20process%20until%20the%20maximum%20error%20is%20within%20the%20tolerance%20we%20set.%20%5C%5C%20%5Cend%7Benumerate%7D%20%5C%5C%20%20%5C%5C%20Note%20here%20that%20this%20differs%20from%20the%20original%20convex%20optimisation%20problem%20in%20that%20we%20aren't%20directly%20minimising%20%24%5Cdelta_%7Bstop%7D%24%2C%20but%20are%20instead%20minimising%20the%20error%20function%20overall%20to%20within%20the%20set%20tolerance.%20I%20started%20off%20by%20making%20the%20ideal%20FIR%20function%20(i.e.%20the%20function%20with%20respect%20to%20which%20the%20error%20is%20calculated)%20a%20low%20pass%20FIR%20filter%2C%20with%20a%20linear%20decrease%20from%201%20to%200%20from%20%24f_%7Bpass%7D%24%20to%20%24f_%7Bstop%7D%24.%20This%20however%20results%20in%20much%20weaker%20stopband%20suppression%20than%20if%20we%20used%20the%20other%20method%2C%20since%20it%20tries%20to%20minimise%20the%20error%20in%20the%20passband%20as%20well%20(i.e.%20keep%20the%20transfer%20function%20as%20close%20to%201%20as%20possible.)%20This%20was%20fixed%20by%20giving%20the%20stopband%20a%20much%20higher%20weight%2C%20thus%20ensuring%20that%20it%20was%20minimised%20at%20the%20cost%20of%20the%20passband.%20Thus%20the%20only%20conditions%20on%20the%20filter%20are%20(i)%20%24G(%5Comega)%20%3D%201%24%20for%20%24%5Comega%20%3D%200%24%20and%20(ii)%20minimising%20%24G(%5Comega)%24%20for%20%24%5Comega%20%3E%20%5Comega_%7Bstop%7D%24.%20This%20gives%20us%20results%20nearly%20identical%20to%20if%20we%20use%20convex%20optimisation%20in%20the%20frequency%20domain.%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%200.8%5D%7Bideal.png%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20%5Csubsection%7BMethod%202%3A%20Convex%20optimisation%20in%20FA%7D%20%5C%5C%20%20%5C%5C%20Here%2C%20we%20want%20to%20optimise%20for%20%24H(%5Comega)%24%20as%20in%20%24(7)%24%2C%20but%20we%20cannot%20apply%20passband%20and%20stopband%20constraints%20to%20%24H(%5Comega)%24%20and%20treat%20it%20as%20a%20convex%20problem%2C%20so%20we%20apply%20a%20change%20of%20variable%2C%20using%20the%20idea%20of%20autocorrelation%20coefficients%20%24r(t)%20%3D%20%5Csum_%7Bi%20%3D%20-n%2B1%7D%5E%7Bn-1%7D%20h(i)h(i%2Bt)%24.%20We%20then%20get%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20R(%5Comega)%20%3D%20%5Csum_%7Bt%5Cin%20Z%7D%20r(t)%20e%5E%7B-j%5Comega%20t%7D%20%3D%20r(0)%20%2B%20%5Csum_%7Bi%3D1%7D%5E%7Bn-1%7D2r(t)cos(%5Comega%20t)%20%3D%20%7CH(%5Comega)%5E2%7C%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20This%20is%20now%20a%20convex%20problem%20in%20%24r(t)%24%2C%20so%20we%20apply%20the%20same%20constraints%20on%20the%20squared%20magnitude%20of%20%24H(%5Comega)%24%20to%20obtain%20the%20optimum%20values%20of%20%24r(t)%24.%20%5C%5C%20%20%5C%5C%20In%20the%20results%20below%20I%20took%20%24H(f)%24%20to%20be%20a%20single%20pole%20filter.%20While%20a%20non-linear%20programming%20solver%20can%20be%20used%20to%20solve%20this%20problem%20in%20its%20existing%20form%2C%20we%20can%20describe%20it%20in%20convex%20form%20by%20approximating%20it%20and%20enforcing%20a%20change%20of%20variable.%20%5C%5C%20%20%5C%5C%20First%2C%20we%20describe%20the%20FA%20response%20for%20a%20discrete%20time%20variant%2C%20with%20a%20pre-sampling%20rate%20of%20%24NF_s%24%20(ensuring%20N%20is%20sufficiently%20large%20such%20that%20the%20aliases%20due%20to%20the%20pre-sampling%20are%20in%20a%20frequency%20range%20that%20is%20sufficiently%20suppressed.)%20This%20gives%20us%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20G(%5Comega)%20%3D%20%5Csum_%7Bm%3D-%5Cfrac%7BN-1%7D%7B2%7D%7D%5E%7B%2B%5Cfrac%7BN-1%7D%7B2%7D%7D%20D_m%20H(%5Comega%20%2B%20%5Cfrac%7B2%5Cpi%20m%7D%7BN%7D)%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20where%20%24D_m%20%3D%20D(%5Cfrac%7B2%5Cpi%20m%7D%7BN%7D)%24.%20Given%20the%20frequency%20response%20%24H(%5Comega)%20%3D%20%5Cfrac%7B1%7D%7B1%20-%20%5Calpha%20e%5E%7B-j%5Comega%7D%7D%24%20and%20(6)%2C%20we%20can%20rewrite%20it%20as%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20G(%5Comega)%20%3D%20%5Cfrac%7B%5Csum_%7Bm%20%3D%20-(N-1)%2F2%7D%5E%7B(N-1)%2F2%7DD_m%20%5Cprod_%7B%5Cmu%20%5Cneq%20m%7D(1-%5Calpha%20e%5E%7Bj(%5Comega%20%2B%20%5Cfrac%7B2%5Cpi%5Cmu%7D%7BN%7D)%7D)%7D%7B%5Cprod_%7B%5Cmu%20%5Cneq%20m%7D%5E%7B(N-1)%2F2%7D%20(1-%5Calpha%20e%5E%7Bj(%5Comega%2B%5Cfrac%7B2%5Cpi%20m%7D%7BN%7D)%7D)%7D%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20We%20write%20this%20in%20terms%20of%20time%20domain%20samples%20%24d%5Bk%5D%24%2C%20giving%20us%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20G(%5Comega)%20%3D%20%5Cfrac%7B%5Csum_%7Bk%3D0%7D%5E%7BN-1%7Dd%5B-k%5D%5Calpha%5Ek%20e%5E%7B-j%5Comega%20k%7D%7D%7B1%20-%20%5Calpha%5EN%20e%5E%7B-j%5Comega%20N%7D%7D%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20We%20can%20now%20adapt%20the%20idea%20explained%20above%20to%20convert%20the%20constraints%20on%20%24G(%5Comega)%24%20to%20a%20convex%20problem.%20We%20write%20the%20squared%20magnitude%20of%20%24G(%5Comega)%24%20(say%20%24R(%5Comega)%24)%20in%20terms%20of%20the%20autocorrelation%20coefficients%20of%20%24g%5Bk%5D%20%3D%20h%5Bk%5Dd%5B-k%5D%24%2C%20%24r(t)%20%3D%20%5Csum_%7Bi%20%3D%20-n%2B1%7D%5E%7Bn-1%7D%20g(i)g(i%2Bt)%24%2C%20where%20%24h%5Bk%5D%20%3D%20%5Calpha%5Ek%24.%20Since%20the%20denominator%20is%20independent%20of%20%24%5Calpha%24%20and%20%24d%5Bk%5D%24%2C%20we%20can%20treat%20the%20numerator%20as%20an%20FIR%20filter.%20This%20finally%20gives%20us%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bequation%7D%20%5C%5C%20%20%20%20%20R(%5Comega)%20%3D%20%20r(0)%20%2B%20%5Csum_%7Bi%3D1%7D%5E%7Bn-1%7D2r(t)cos(%5Comega%20t)%20%3D%20%7C1-%5Calpha%5ENe%5E%7B-j%5Comega%20N%7D%7CH(%5Comega)%5E2%20%5C%5C%20%5Cend%7Bequation%7D%20%5C%5C%20%20%5C%5C%20Optimising%20%24%7CH(%5Comega)%5E2%7C%24%20is%20a%20convex%20problem%2C%20as%20it%20is%20a%20linear%20combination%20of%20the%20optimisation%20variables%20%24r(t)%24%2C%20and%20so%20we%20can%20have%20lower%20bounds%20for%20%24R(%5Comega)%24%20as%20required%20by%20the%20passband%20constraint.%20Once%20we%20have%20the%20problem%20in%20this%20form%2C%20a%20package%20like%20cvx%20can%20be%20used%20to%20give%20the%20optimal%20value%20of%20%24d%5Bk%5D%24%2C%20minimising%20%24%5Cdelta_%7Bstop%7D%24.%20To%20determine%20%24d%5Bk%5D%24%20from%20this%2C%20we%20apply%20spectral%20factorisation%20on%20%24R(%5Comega)%24%20to%20determine%20the%20minimum%20phase%20%24G(%5Comega)%24.%20There%20is%20then%20a%20one-one%20correlation%20between%20%24G(%5Comega)%24%2C%20and%20%24d%5Bk%5D%24%20and%20%24%5Calpha%24%20(although%20here%20%24%5Calpha%24%20was%20taken%20to%20be%20fixed)%2C%20finally%20giving%20us%20the%20desired%20signal%20%24d(t)%24.%20%5C%5C%20%20%5C%5C%20%5Csection%7BIssues%7D%20%5C%5C%20%20%5C%5C%20I%20was%20not%20able%20to%20demonstrate%20this%20in%20LTSpice%20as%20it%20could%20not%20handle%20delta%20functions%20(which%20the%20signal%20d(t)%20consists%20of%20as%20a%20periodic%20function)%20well%20when%20plotting%20the%20frequency%20response%2C%20so%20I%20plotted%20the%20transfer%20function%20in%20MATLAB%20instead%2C%20assuming%20a%20single%20pole%20RC%20filter.%20While%20solving%20by%20convex%20factorisation%2C%20I%20was%20also%20unable%20to%20recover%20the%20minimum%20phase%20%24G(%5Comega)%24%20from%20%24%7CG(%5Comega)%5E2%7C%24%20as%20described%20in%20the%20paper%20as%20the%20MATLAB%20function%20spectralfact%20was%20not%20able%20to%20process%20the%20transfer%20function.%20I%20tried%20using%20the%20autocorrelation%20coefficients%20to%20obtain%20the%20original%20%24d(t)%24%20as%20outlined%20in%20the%20paper%20above%2C%20but%20was%20again%20unable%20to%20obtain%20an%20output%20from%20the%20function.%20However%2C%20these%20issues%20were%20solved%20using%20the%20Parks-McClellan%20algorithm.%20%20%5C%5C%20%20%5C%5C%20%5Csection%7BOther%20Considerations%7D%20%5C%5C%20%20%5C%5C%20When%20implementing%20FA%20in%20practical%20applications%2C%20there%20are%20some%20additional%20considerations.%20First%2C%20the%20spreader%20signal%20%24d(t)%24%20has%20a%20finite%20resolution%2C%20and%20so%20the%20stopband%20suppression%20depends%20on%20the%20quantisation%20error.%20Aside%20from%20increasing%20the%20number%20of%20bits%2C%20this%20error%20can%20also%20be%20reduced%20by%20dithering%2C%20which%20is%20intentionally%20adding%20noise%20before%20quantisation%20to%20reduce%20the%20effect%20of%20the%20periodicity%20of%20the%20quantisation%20noise.%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%201%5D%7Bfinal.png%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20As%20discussed%20earlier%2C%20the%20spreader%20rate%20(or%20%24NF_s%24)%20also%20affects%20the%20performance%20of%20the%20filter.%20This%20is%20because%20the%20gain%20stage%20(where%20the%20spreading%20signal%20is%20mixed%20with%20the%20input)%2C%20is%20digitally%20controlled%20with%20frequency%20%24NF_s%24.%20As%20long%20as%20%24N%24%20is%20sufficiently%20high%20however%2C%20the%20impact%20of%20the%20aliased%20pass-bands%20is%20negligible%20as%20usually%2C%20the%20rest%20of%20the%20circuit%20is%20inherently%20low-pass.%20%5C%5C%20%20%5C%5C%20%5Csection%7BFinal%20Results%7D%20%5C%5C%20%20%5C%5C%20The%20magnitude%20of%20the%20FA%20filter%20%24%7CG(%5Comega)%7C%24%20is%20plotted%20below%20for%20different%20values%20of%20%24f_%7Bstop%7D%24%20along%20with%20the%20frequency%20response%20of%20a%20single%20pole%20filter%20(with%20%24%5Calpha%20%3D%200.9%24.)%20From%20the%20plots%20it%20is%20clear%20that%20the%20dropoff%20is%20much%20faster%20for%20an%20FA%20filter%2C%20and%20the%20stopband%20suppression%20is%20greatly%20improved.%20As%20can%20be%20seen%20from%20the%20plots%2C%20a%20balance%20has%20to%20be%20struck%20between%20how%20fast%20the%20dropoff%20is%20(determined%20by%20%24f_%7Bstop%7D%24)%20and%20the%20stopband%20suppression%20(%24%5Cdelta_%7Bstop%7D%24%2C%20the%20variable%20minimised%20while%20optimising.)%20We%20have%20also%20compared%20the%20results%20from%20the%20two%20methods%20used%20to%20find%20the%20optimal%20transfer%20function%2C%20%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%200.8%5D%7Blogcomb.png%7D%20%5C%5C%20%5Ccaption%7BUsing%20convex%20optimisation%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%200.8%5D%7Blog_parks.png%7D%20%5C%5C%20%5Ccaption%7BUsing%20Parks-McClellan%20algorithm%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20%5Cbegin%7Bfigure%7D%5Bh!%5D%20%5C%5C%20%5Ccentering%20%5C%5C%20%5Cincludegraphics%5Bscale%20%3D%200.8%5D%7Bcomparison.png%7D%20%5C%5C%20%5Ccaption%7BComparing%20the%20two%20methods%20with%20%24f_%7Bstop%7D%20%3D%201.5F_s%24%7D%20%5C%5C%20%5Cend%7Bfigure%7D%20%5C%5C%20%20%5C%5C%20%20%5C%5C%20%5Cend%7Bdocument%7D%20%5C%5C%20)](#_)
